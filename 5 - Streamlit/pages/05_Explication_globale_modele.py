import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import shap
import pickle
from PIL import Image
import os


# Configuration de la page
st.set_page_config(
        page_title='Interpr√©tation Globale de la pr√©diction',
        layout="wide" )

# Lecture des fichiers
# Chargement du mod√®le
model_path = os.path.join("Modeles", "best_model_LGBM_resampled.pkl")
model = pickle.load(open(model_path, "rb"))
target_names = ["indemne", "tu√©", "bless√©_hospitalis√©", "bless√©_l√©ger"] #list(model.classes_)
# Rappel des num√©ros des classes et de leur libell√©
# 1:"indemne"
# 2:"tu√©"
# 3:"bless√©_hospitalis√©"
# 4:"bless√©_l√©ger"

# Chargement des valeurs Shap
shap_path = os.path.join('Modeles', 'shap_values_lgbm_all.pkl')
shap_values_all = pickle.load(open(shap_path, "rb"))

@st.cache_data #mise en cache de la fonction
def load_data():
    data_path = os.path.join('Data', 'X_test.csv')
    df = pd.read_csv(data_path, index_col=0)
    return df

X_test = load_data()
feature_names = X_test.columns.tolist()

# Titre 1
st.markdown("""
            <h1>
            9. Quelles sont les variables globalement les plus importantes pour comprendre la pr√©diction ?
            </h1>
            """, 
            unsafe_allow_html=True)
st.write("")

st.write("""
         **Rappel sur l'interpr√©tabilit√© d'un mod√®le**
         
         L‚Äôinterpr√©tabilit√© correspond √† la mesure dans laquelle un √™tre humain peut pr√©dire de mani√®re coh√©rente
         le r√©sultat d‚Äôun mod√®le. Plus l'interpr√©tabilit√© d'un mod√®le de Machine Learning est √©lev√©e,
         plus il est facile pour un individu de comprendre le raisonnement derri√®re certaines d√©cisions ou pr√©dictions.
         Un mod√®le est plus facilement interpr√©table qu'un autre si ses d√©cisions sont plus faciles √† comprendre pour un humain.
    """)

st.write("""
         **Interpr√©tation de mod√®le avec SHAP**
         
         SHAP pour *SHapley Additive exPlanations* est une librairie Python proposant une approche unifi√©e pour
         expliquer le r√©sultat de tout mod√®le de Machine Learning. Elle utilise la th√©orie des jeux pour attribuer
         une importance √† chaque variable (feature) d'entr√©e en mesurant la contribution marginale de chaque feature
         √† la pr√©diction finale.
         
         SHAP permet de r√©pondre √† la question : **¬´ Pourquoi le mod√®le a-t-il pr√©dit cette valeur ? ¬ª**.
         Elle fournit ainsi des explications claires et compr√©hensibles pour les d√©cideurs et les utilisateurs finaux,
         ce qui renforce la transparence et la confiance dans les pr√©dictions du mod√®le.
    """)

st.write("""
         L‚Äôimportance des variables est calcul√©e en moyennant la valeur absolue des valeurs de Shap.
         Les caract√©ristiques sont class√©es de l'effet le plus √©lev√© au plus faible sur la pr√©diction.
         Le calcul prend en compte la valeur SHAP absolue, donc peu importe si la fonctionnalit√© affecte
         la pr√©diction de mani√®re positive ou n√©gative.
    """)

st.write("""
         *__Le diagramme d'importance des variables__* r√©pertorie les variables les plus significatives par ordre d√©croissant.
        Les *__variables en haut__* contribuent davantage au mod√®le que celles en bas et ont donc un *__pouvoir pr√©dictif √©lev√©__*.
        
        Puisque nous traitons une t√¢che de classification multi-classes, le trac√© r√©capitulatif classe les variables
        en fonction de leur contribution globale √† toutes les classes et code en couleur l'ampleur de chaque classe.
    """)

fig = plt.figure()
shap.summary_plot(shap_values_all,
                X_test,
                plot_type="bar",
                class_names=target_names,
                feature_names=feature_names,
                plot_size=(16, 12),
                max_display=33,
                show=False)
plt.title(
    "Importance des features dans la construction du mod√®le LGBM multi-classes",
    fontsize=20,
    fontstyle='italic')
plt.tight_layout()
st.pyplot(fig)

st.write("***Ainsi, la pr√©sence ou non de la ceinture lors de l'accident est la variable qui contribue le plus √† la performance \
         du mod√®le LGBM multi-classes et surtout pour la pr√©diction des personnes 'indemnes'.***")

# Titre
st.markdown("""
            <h1>
            10. Quel est l'Impact de chaque caract√©ristique sur la pr√©diction de chaque classe ?
            </h1>
            """, 
            unsafe_allow_html=True)
st.write("")

st.write("Les diagrammes des valeurs SHAP ci-dessous indique √©galement comment chaque caract√©ristique impacte la pr√©diction. \
        Les valeurs de Shap sont repr√©sent√©es pour chaque variable dans leur ordre d‚Äôimportance. \
        Chaque point repr√©sente une valeur de Shap (c'est-√†-dire un usager accident√© de la route.")
st.write("")

fig = plt.figure()
ax0 = fig.add_subplot(221)
shap.summary_plot(shap_values_all[0], 
                  features=X_test,
                  feature_names=feature_names,
                  class_names= target_names,
                  cmap='PiYG_r',
                  plot_type="dot",
                  max_display=15,
                  show = False)
plt.title(f"Interpr√©tation Globale de la classe {target_names[0]}\n", 
          fontsize=20, fontstyle='italic', fontweight='bold')

ax1 = fig.add_subplot(222)
shap.summary_plot(shap_values_all[1], 
                  features=X_test,
                  feature_names=feature_names,
                  class_names= target_names,
                  cmap='PiYG_r',
                  plot_type="dot",
                  max_display=15,
                  show = False)
plt.title(f"Interpr√©tation Globale de la classe {target_names[1]}\n", 
          fontsize=20, fontstyle='italic', fontweight='bold')

ax2 = fig.add_subplot(223)
shap.summary_plot(shap_values_all[2], 
                  features=X_test,
                  feature_names=feature_names,
                  class_names= target_names,
                  cmap='PiYG_r',
                  plot_type="dot",
                  max_display=15,
                  show = False)
plt.title(f"\nInterpr√©tation Globale de la classe {target_names[2]}\n", 
          fontsize=20, fontstyle='italic', fontweight='bold')

ax3 = fig.add_subplot(224)
shap.summary_plot(shap_values_all[3], 
                  features=X_test,
                  feature_names=feature_names,
                  class_names= target_names,
                  cmap='PiYG_r',
                  plot_type="dot",
                  max_display=15,
                  show = False)
plt.title(f"\nInterpr√©tation Globale de la classe {target_names[3]}\n", 
          fontsize=20, fontstyle='italic', fontweight='bold')
plt.gcf().set_size_inches(24,16)
plt.tight_layout() 
st.pyplot(plt.gcf())

plt.clf()  # Nettoyez la figure courante


# Titre 
st.markdown("""
            <h1>
            11. Interpr√©tation des pr√©dictions par classe
            </h1>
            """, 
            unsafe_allow_html=True)
st.write("""
         Nous pouvons obtenir un aper√ßu plus approfondi de l'effet de chaque feature
         pour chaque classe sur l'ensemble de donn√©es avec un graphique de d√©pendance.
    """)


# Cr√©ation et affichage du s√©lecteur des variables et des graphs de d√©pendance
feature_names = sorted(feature_names)
col1, col2, = st.columns(2) # division de la largeur de la page en 2 pour diminuer la taille du menu d√©roulant
with col1:
    ID_var = st.selectbox("*Veuillez s√©lectionner une variable √† l'aide du menu d√©roulant üëá*", 
                            (feature_names), index=0)
    st.write("Vous avez s√©lectionn√© la variable :", ID_var)

st.write(f"Les cat√©gories de la variable **{ID_var}** sont sur l'axe des abscisses.")

st.write("""
         Pour chaque classe, les valeurs de SHAP les plus √©lev√©es indiquent les cat√©gories de la variable d'entr√©e
         qui ont le plus grand impact sur les pr√©dictions du mod√®le.
    """)

fig = plt.figure()
ax0 = fig.add_subplot(222)
shap.dependence_plot(ID_var, 
                     shap_values_all[0], 
                     X_test, 
                     interaction_index=None,
                     alpha=0.5,
                     ax=ax0, 
                     show = False)
plt.title(f"Graphique de d√©pendance\nVariable : '{ID_var}'\nClasse : '{target_names[0]}'",
          fontsize=20,
          fontstyle='italic')

ax1 = fig.add_subplot(223)
shap.dependence_plot(ID_var, 
                     shap_values_all[1], 
                     X_test, 
                     interaction_index=None, 
                     alpha=0.5,
                     ax=ax1, show = False)
plt.title(f"Graphique de d√©pendance\nVariable : '{ID_var}'\nClasse : '{target_names[1]}'",
          fontsize=20,
          fontstyle='italic')

ax2 = fig.add_subplot(224)
shap.dependence_plot(ID_var, 
                     shap_values_all[2], 
                     X_test, 
                     interaction_index=None,
                     alpha=0.5,
                     ax=ax2, show = False)
plt.title(f"Graphique de d√©pendance\nVariable : '{ID_var}'\nClasse : '{target_names[2]}'",
          fontsize=20,
          fontstyle='italic')

ax3 = fig.add_subplot(221)
shap.dependence_plot(ID_var, 
                     shap_values_all[3], 
                     X_test, 
                     interaction_index=None, 
                     alpha=0.5,
                     ax=ax3, show = False)
plt.title(f"Graphique de d√©pendance\nVariable : '{ID_var}'\nClasse : '{target_names[3]}'",
          fontsize=20,
          fontstyle='italic')

plt.gcf().set_size_inches(24,16)
plt.tight_layout()
st.pyplot(plt.gcf())

plt.clf()  # Nettoyez la figure courante


# Centrage de l'image du logo dans la sidebar
col1, col2, col3 = st.columns([1,1,1])
with col1:
    st.sidebar.write("")
with col2:
    image_path = os.path.join('Photo', 'logo-datascientest.png')
    logo = Image.open(image_path)
    st.sidebar.image(logo, use_column_width="always")
with col3:
    st.sidebar.write("")

